{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看tensorflow版本\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow下载minist数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#分别查看训练集和测试集的特征、标签的大小\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(img):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=cm.binary)\n",
    "# output image     \n",
    "display(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#同时打印出图片对应的标签的数值\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "#统计标签y的个数\n",
    "labels_count = len(set(y_train))\n",
    "print (labels_count)\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1 = X_train.reshape(60000,784)\n",
    "X_test1 = X_test.reshape(10000,784)\n",
    "X_train1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = dense_to_one_hot(y_train, labels_count)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(50000,784)\n",
      "validation_images(10000,784)\n"
     ]
    }
   ],
   "source": [
    "# split data into training & validation,将全部的训练集分为训练集和验证集\n",
    "validation_images = X_train1[:10000]\n",
    "validation_labels = train_labels[:10000]\n",
    "train_images = X_train1[10000:]\n",
    "train_labels = train_labels[10000:]\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置学习率\n",
    "LEARNING_RATE = 1e-3\n",
    "#训练总次数，迭代100\n",
    "TRAINING_ITERATIONS = 1000 \n",
    "\n",
    "#随机不连接的神经元占比为50%    \n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "#设置读入的图片的大小\n",
    "image_width =28\n",
    "image_height = 28\n",
    "image_size = image_width*image_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight initialization，初始化权重矩阵，初始化为服从正态分布的随机变量\n",
    "#shape是指某一层输入和输出的个数\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#偏差bias初始化为常量0.1\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积，tf.nn.conv2d函数是tensoflow里面的二维的卷积函数，\n",
    "#x是图片的所有参数，W是此卷积层的权重，然后定义步长strides=[1,1,1,1]值，\n",
    "#strides[0]和strides[3]的两个1是默认值，中间两个1代表padding时在x方向运动一步，y方向运动一步，padding采用的方式是valid，但是此时效果与padding取same相同\n",
    "#padding是边框填充的参数，取值为same和valid，padding取valid是在convolution层若filter后只剩下1列或不够filter列时，直接将数据丢弃，但是padding取same会自动在后面填充0，继续filter\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义池化函数pooling，为了得到更多的图片信息，padding时我们选的是一次一步，\n",
    "#也就是strides[1]=strides[2]=1，这样得到的图片尺寸没有变化，\n",
    "#而我们希望压缩一下图片也就是参数能少一些从而减小系统的复杂度，\n",
    "#因此我们采用pooling来稀疏化参数，也就是卷积神经网络中所谓的下采样层。\n",
    "#pooling 有两种，一种是最大值池化，一种是平均值池化，本例采用的是最大值池化tf.max_pool()。\n",
    "#池化的核函数大小为2x2，因此ksize=[1,2,2,1]，步长为2，因此strides=[1,2,2,1]:\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images,输入是未知个数的图片特征，每个图片为784维，里面每个元素类型是浮点型\n",
    "x = tf.placeholder('float', shape=[None, image_size])\n",
    "# labels，标签是未知个数，但是每个标签的维度是10\n",
    "y_ = tf.placeholder('float', shape=[None, labels_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义整个LeNet5的网络结构\n",
    "\n",
    "# 定义第一层卷积,先定义本层的Weight,本层我们的卷积核的大小是5x5，因为黑白图片channel是1所以输入是1，输出是6个featuremap\n",
    "W_conv1 = weight_variable([5, 5, 1, 6])\n",
    "b_conv1 = bias_variable([6])\n",
    "\n",
    "#把xs的形状变成[-1,28,28,1]，-1代表先不考虑输入的图片例子多少这个维度，\n",
    "#后面的1是channel的数量，因为我们输入的图片是黑白的，因此channel是1，例如如果是RGB图像，那么channel就是3。\n",
    "# (50000,784) => (50000,28,28,1)\n",
    "image = tf.reshape(x, [-1,image_width , image_height,1])\n",
    "#print (image.get_shape()) # =>(50000,24,24,1)\n",
    "\n",
    "#定义卷积神经网络的第一个卷积层h_conv1=conv2d(x_image,W_conv1)+b_conv1,\n",
    "#同时我们对h_conv1进行非线性处理，也就是激活函数来处理喽，\n",
    "#这里我们用的是tf.nn.relu（修正线性单元）来处理，要注意的是，\n",
    "#因为采用了SAME的padding方式，输出图片的大小没有变化依然是24x24，只是厚度变厚了，因此现在的输出大小就变成了24x24x6\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1)\n",
    "#print (h_conv1.get_shape()) # => (50000, 24, 24, 6)\n",
    "\n",
    "#第一个pooling层，经过max_pooling输出变成14x14x6\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "#print (h_pool1.get_shape()) # => (50000, 12, 12, 6)\n",
    "\n",
    "#第二个卷积层,本层我们的卷积核的大小是5x5，因为channel是第一个pool层输出的6，输出是16个featuremap\n",
    "W_conv2 = weight_variable([5, 5, 6, 16])\n",
    "b_conv2 = bias_variable([16])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "#print (h_conv2.get_shape()) # => (50000, 8, 8, 16)\n",
    "\n",
    "#第二个pooling层，经过max_pooling输出变成14x14x16\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "#print (h_pool1.get_shape()) # => (50000, 4, 4, 16)\n",
    "\n",
    "#第5层，第一个全连接层,上一个池化层的经过flatten是256个神经元\n",
    "conv_layer_flatten = tf.layers.flatten(inputs = h_pool2)\n",
    "fc1_variable = weight_variable([256, 120])\n",
    "fc1_bias = bias_variable(shape = [1, 120])\n",
    "fc1 = tf.nn.relu(tf.add(tf.matmul(conv_layer_flatten, fc1_variable), fc1_bias))   \n",
    "\n",
    "#第六层，第二个全连接层，该层的神经元个数是120\n",
    "fc2_variable = weight_variable([120,84]) \n",
    "fc2_bias = bias_variable(shape=[1, 84])\n",
    "fc2 = tf.nn.relu(tf.add(tf.matmul(fc1, fc2_variable), fc2_bias))            \n",
    "        \n",
    "#第七层，第三个全连接层\n",
    "output_variable = weight_variable([84, 10])\n",
    "output_bias = bias_variable(shape = [1, 10])\n",
    "y = tf.add(tf.matmul(fc2, output_variable), output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function,分类问题的损失函数用cross_entropy\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# optimisation function,优化函数\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "# evaluation，根据输出层的最大的Y值为输出的标签\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "#训练样本个数\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    #从哪一个样本开始训练，每次用batch_sice个样本\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm) #随机打乱所有的样本集\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#神经网络的初始化，包括参数初始化和session初始化，以下的初始化语句必须有\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.11 / 0.10 for step 0\n",
      "training_accuracy / validation_accuracy => 0.13 / 0.10 for step 1\n",
      "training_accuracy / validation_accuracy => 0.06 / 0.10 for step 2\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.10 for step 3\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.10 for step 4\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.10 for step 5\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.10 for step 6\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.10 for step 7\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.10 for step 8\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.10 for step 9\n",
      "training_accuracy / validation_accuracy => 0.06 / 0.10 for step 10\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.10 for step 20\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.10 for step 30\n",
      "training_accuracy / validation_accuracy => 0.14 / 0.16 for step 40\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.16 for step 50\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.16 for step 60\n",
      "training_accuracy / validation_accuracy => 0.07 / 0.16 for step 70\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.16 for step 80\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.16 for step 90\n",
      "training_accuracy / validation_accuracy => 0.11 / 0.16 for step 100\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.16 for step 200\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.16 for step 300\n",
      "training_accuracy / validation_accuracy => 0.09 / 0.16 for step 400\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.16 for step 500\n",
      "training_accuracy / validation_accuracy => 0.07 / 0.16 for step 600\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.16 for step 700\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.16 for step 800\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.16 for step 900\n",
      "training_accuracy / validation_accuracy => 0.13 / 0.16 for step 999\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "x_range = []\n",
    "#每隔几次输出当前的训练误差和验证误差\n",
    "display_step=1\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "    #get new batch\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE)        \n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_xs, \n",
    "                                                  y_: batch_ys})       \n",
    "        if(VALIDATION_SIZE):\n",
    "            validation_accuracy = accuracy.eval(feed_dict={ x: validation_images[0:BATCH_SIZE], \n",
    "                                                            y_: validation_labels[0:BATCH_SIZE]})                                  \n",
    "            print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "            \n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "            \n",
    "        else:\n",
    "             print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        x_range.append(i)\n",
    "        \n",
    "        # increase display_step\n",
    "        if i%(display_step*10) == 0 and i:\n",
    "            display_step *= 10\n",
    "    # train on batch\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
